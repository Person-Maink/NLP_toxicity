


!python -m spacy download en_core_web_sm huggingface_hub transformers

import pandas as pd
import ast 
import numpy as np
from huggingface_hub import login
from transformers import AutoTokenizer
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import spacy
from scipy.stats import spearmanr
import matplotlib.pyplot as plt
from scipy.stats import ttest_ind
import ast
import re





def read_attribution_scores(file_path):
    def parse_array_or_matrix(value):
        try:
            # print(ast.literal_eval(value))
            return np.array(ast.literal_eval(value), dtype=float) # Safely convert string representation to Python list
        except (ValueError, SyntaxError):
            # print("error")
            return value  # Return as-is if it cannot be parsed

    df = pd.read_csv(
        file_path,
        converters={
            'Input Token Attributions': parse_array_or_matrix,
            'Output Token Attributions': parse_array_or_matrix,
        }
    )

    return df

def read_all_attribution_scores(): 
    mistral = 'Mistral/attribution_results_mistral_top_10.csv'
    bloom = 'Bloom/attribution_results_bloom_top_10.csv'
    llama = 'Llama/attribution_results_llama_top_10.csv'

    mistral_df = read_attribution_scores(mistral)
    mistral_df['Model'] = 'Mistral'

    bloom_df = read_attribution_scores(bloom)
    bloom_df['Model'] = 'Bloom'

    llama_df = read_attribution_scores(llama)
    llama_df['Model'] = 'Llama'

    combined_df = pd.concat([mistral_df, bloom_df, llama_df], ignore_index=True)

    return combined_df    


df = read_all_attribution_scores()
df.head()





# load tokenizers and get tokens for all the prompts
login("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")
llama_tokenizer = AutoTokenizer.from_pretrained("meta-llama/Meta-Llama-3-8B")

login("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")
mistral_tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-v0.1") 

bloom_tokenizer = AutoTokenizer.from_pretrained("bigscience/bloom-7b1")

tokenizers = {'Llama':llama_tokenizer,
              "Mistral":mistral_tokenizer, 
              "Bloom":bloom_tokenizer}

def create_clean_token(text, tokenizer): 
    tokens = tokenizer.tokenize(text)
    ret = [token.replace('Ġ', '').replace('▁', '').replace('##', '').replace("<0x0A>", "[NL]") for token in tokens if token not in tokenizer.all_special_tokens]
    assert(len(ret) == len(tokens))
    return ret


def map_attributions_to_tokens(row, tokenizer, top_percentile_general=80, top_percentile_to_output=90):
    # Tokenize the prompt and response
    tokenized_prompt = create_clean_token(row["Prompt"], tokenizer)
    tokenized_response = create_clean_token(row["Response"], tokenizer)

    input_attributions = row["Input Token Attributions"]
    output_attributions = row["Output Token Attributions"].T  # transpose the matrix (now: rows correspond to input tokens and column corresponds to response tokens)

    # handle mismatched stuff   
    if row["Model"] == "Llama" and len(tokenized_prompt) < output_attributions.shape[0]:
        output_attributions = output_attributions[:-1]
        input_attributions = input_attributions[:-1]
        
    if row["Model"] == "Bloom" and len(tokenized_response) > output_attributions.shape[1]:
        tokenized_response = tokenized_response[:-1]

    # print(len(tokenized_prompt))
    # print(len(input_attributions))
    # print(len(tokenized_response))
    # print(output_attributions.shape)
    if len(tokenized_prompt) != len(input_attributions):
        raise ValueError(f"Mismatch between tokenized prompt and input attributions for row:\n{row}")
    if output_attributions.shape[0] != len(tokenized_prompt) or output_attributions.shape[1] != len(tokenized_response):
        raise ValueError(f"Mismatch in output attribution matrix dimensions for row:\n{row}")

    # print(row["Prompt"])
    # print(word_tokens_prompt)
    # print(word_tokens_response)
    
    # ----------------------------------------------------------------------------
    # PART A: High Input Tokens (General) using relative threshold
    # ----------------------------------------------------------------------------
    # Calculate the percentile cutoff (e.g., 90th for top 10%).
    general_cutoff = np.percentile(input_attributions, top_percentile_general)

    # Select tokens whose attributions exceed that cutoff
    high_input_tokens_general = [
        tokenized_prompt[i] for i, score in enumerate(input_attributions)
        if score > general_cutoff
    ]

    # ----------------------------------------------------------------------------
    # PART B: High Input Tokens (Column Max)
    # ----------------------------------------------------------------------------
    # 1. For each response token (i.e., each column j), find:
    #       the row i that yields the maximum attribution for that column.
    # 2. Collect these maxima across all columns into a list.
    # 3. We'll then apply a percentile cutoff to those maxima, so we only keep
    #    the columns where the max attribution is "really" high.

    num_input_tokens, num_output_tokens = output_attributions.shape
    max_influence_per_column = []        # max attribution value for each column
    max_influence_index_per_column = []  # which input token index had that max value

    for j in range(num_output_tokens):
        col_vals = output_attributions[:, j]  # all input->that output token j
        max_i = np.argmax(col_vals)           # which input token had the max influence?
        max_val = col_vals[max_i]            # that max attribution score
        max_influence_per_column.append(max_val)
        max_influence_index_per_column.append(max_i)

    # 4. Compute the percentile cutoff across all column-max values
    col_max_cutoff = np.percentile(max_influence_per_column, top_percentile_to_output)
    
    # 5. Now pick which input tokens appear in columns whose max is above the cutoff
    high_input_tokens_wrt_output_indices = set()
    for j, max_val in enumerate(max_influence_per_column):
        if max_val > col_max_cutoff:
            # which input token was max for this column?
            max_i = max_influence_index_per_column[j]
            high_input_tokens_wrt_output_indices.add(max_i)

    high_input_tokens_wrt_output = [
        tokenized_prompt[i] for i in sorted(high_input_tokens_wrt_output_indices)
    ]

    # print(tokenized_prompt)
    # print(high_input_tokens_general)
    # print(high_input_tokens_wrt_output)
    
    return {
        "Tokenized Prompt": tokenized_prompt,
        "High Input Tokens General": high_input_tokens_general,
        "High Input Tokens To Output": high_input_tokens_wrt_output
    }








nlp = spacy.load("en_core_web_sm")

def analyze_syntax(sentence):
    doc = nlp(sentence)
    syntax = []
    for token in doc:
        syntax.append({
            "Token": token.text,
            "POS": token.pos_,
            "Dependency": token.dep_,
            "Head": token.head.text,
            "Head POS": token.head.pos_,
            "Children": [(child.text, child.dep_, child.pos_) for child in token.children]
        })
    return syntax

def syntactic_analysis_with_tokens(df, tokenizers):
    results = []
    for _, row in df.iterrows():
        model = row["Model"]
        tokenizer = tokenizers[model]

        # these tokens are also filtered so that only the tokens with high attr.
        # scores (wrt their sentence) are selected
        mapped_tokens = map_attributions_to_tokens(row, tokenizer)
        
        # Perform syntactic analysis on the entire prompt
        prompt_text = " ".join(mapped_tokens["Tokenized Prompt"])
        prompt_syntax = analyze_syntax(prompt_text)

        # Use sets for faster lookup
        high_input_tokens_set = set(mapped_tokens["High Input Tokens General"])
        high_output_tokens_set = set(mapped_tokens["High Input Tokens To Output"])

        # Analyze high-attribution tokens in a single pass
        high_input_syntax = []
        high_output_syntax = []
        for token_data in prompt_syntax:
            token_text = token_data["Token"]
            if token_text in high_input_tokens_set:
                high_input_syntax.append(token_data)
            if token_text in high_output_tokens_set:
                high_output_syntax.append(token_data)

        # Append results
        results.append({
            "Prompt": row["Prompt"],
            "Prompt Syntax": prompt_syntax,
            "High General Input Tokens Syntax": high_input_syntax,
            "High Influential Input Tokens Syntax": high_output_syntax,
            "Model": row["Model"]
        })
    return pd.DataFrame(results)





syntactic_results = syntactic_analysis_with_tokens(df, tokenizers)

# print(syntactic_results.head())
print(syntactic_results.info())








position_of_prompt = 1


# Example: Inspecting a single prompt's syntax
example_prompt_syntax = syntactic_results.iloc[position_of_prompt]["Prompt Syntax"]

# Convert to DataFrame for better readability
prompt_syntax_df = pd.DataFrame(example_prompt_syntax)
print(prompt_syntax_df)


# Inspect high-attribution input tokens for a specific row
example_high_input_syntax = syntactic_results.iloc[position_of_prompt]["High General Input Tokens Syntax"]
print(pd.DataFrame(example_high_input_syntax))


# Inspect high-attribution output tokens for a specific row
example_high_output_syntax = syntactic_results.iloc[position_of_prompt]["High Influential Input Tokens Syntax"]
print(pd.DataFrame(example_high_output_syntax))


from spacy import displacy

# Visualize the syntax tree for the first prompt
doc = nlp(syntactic_results.iloc[position_of_prompt]["Prompt"])
displacy.render(doc, style="dep", jupyter=True)








import matplotlib.pyplot as plt

# Dictionary to store aggregated data for all models
all_models_data = {}

# Collect POS frequencies for each model
for model in syntactic_results["Model"].unique():
    model_data = syntactic_results[syntactic_results["Model"] == model]
    
    # Aggregate POS tags for high-input tokens
    pos_counts = pd.Series(
        [entry["POS"] for syntax in model_data["High Influential Input Tokens Syntax"] for entry in syntax]
    ).value_counts()
    
    # Map POS tags to explanations
    pos_explanations = pos_counts.index.map(spacy.explain)
    
    # Add the data to the dictionary
    all_models_data[model] = pd.DataFrame({
        "POS": pos_counts.index,
        "Frequency": pos_counts.values,
        "Explanation": pos_explanations
    })

# Create a unified set of POS explanations (for x-axis consistency)
all_explanations = set()
for data in all_models_data.values():
    all_explanations.update(data["Explanation"])

all_explanations = sorted(all_explanations)  # Sort for consistent x-axis

# Initialize a plot
plt.figure(figsize=(12, 8))

plt.figure(figsize=(12, 8))
for model, data in all_models_data.items():
    aligned_frequencies = [
        data.loc[data["Explanation"] == explanation, "Frequency"].sum() if explanation in data["Explanation"].values else 0
        for explanation in all_explanations
    ]
    plt.plot(all_explanations, aligned_frequencies, label=model, marker='o')

plt.title("POS Distribution Across Models")
plt.xlabel("Part of Speech Explanation")
plt.ylabel("Frequency")
plt.xticks(rotation=45, ha="right")
plt.legend(title="Models")
plt.tight_layout()
plt.show()





import matplotlib.pyplot as plt

# Dictionary to store aggregated data for all models
all_models_data = {}

# Collect POS frequencies for each model
for model in syntactic_results["Model"].unique():
    model_data = syntactic_results[syntactic_results["Model"] == model]
    
    # Aggregate POS tags for high-input tokens
    pos_counts = pd.Series(
        [entry["POS"] for syntax in model_data["High General Input Tokens Syntax"] for entry in syntax]
    ).value_counts()
    
    # Map POS tags to explanations
    pos_explanations = pos_counts.index.map(spacy.explain)
    
    # Add the data to the dictionary
    all_models_data[model] = pd.DataFrame({
        "POS": pos_counts.index,
        "Frequency": pos_counts.values,
        "Explanation": pos_explanations
    })

# Create a unified set of POS explanations (for x-axis consistency)
all_explanations = set()
for data in all_models_data.values():
    all_explanations.update(data["Explanation"])

all_explanations = sorted(all_explanations)  # Sort for consistent x-axis

# Initialize a plot
plt.figure(figsize=(12, 8))

plt.figure(figsize=(12, 8))
for model, data in all_models_data.items():
    aligned_frequencies = [
        data.loc[data["Explanation"] == explanation, "Frequency"].sum() if explanation in data["Explanation"].values else 0
        for explanation in all_explanations
    ]
    plt.plot(all_explanations, aligned_frequencies, label=model, marker='o')

plt.title("POS Distribution Across Models")
plt.xlabel("Part of Speech Explanation")
plt.ylabel("Frequency")
plt.xticks(rotation=45, ha="right")
plt.legend(title="Models")
plt.tight_layout()
plt.show()








# POS frequency for high-input tokens
pos_counts_input = pd.Series(
    [entry["POS"] for syntax in syntactic_results["High General Input Tokens Syntax"] for entry in syntax]
).value_counts()

# Create a DataFrame for high-input tokens with explanations
pos_df_input = pd.DataFrame({
    "POS": pos_counts_input.index,
    "Frequency": pos_counts_input.values,
    "Explanation": pos_counts_input.index.map(spacy.explain)
})

print("POS Frequency and Explanation for High Input Tokens:\n", pos_df_input)
print("----------------------------------------------------------------------------")

# POS frequency for high-output tokens
pos_counts_output = pd.Series(
    [entry["POS"] for syntax in syntactic_results["High Influential Input Tokens Syntax"] for entry in syntax]
).value_counts()

# Create a DataFrame for high-output tokens with explanations
pos_df_output = pd.DataFrame({
    "POS": pos_counts_output.index,
    "Frequency": pos_counts_output.values,
    "Explanation": pos_counts_output.index.map(spacy.explain)
})

print("POS Frequency and Explanation for High Output Tokens:\n", pos_df_output)


import matplotlib.pyplot as plt
import numpy as np

# Align both dataframes to ensure consistency in x-axis (all explanations included)
all_explanations = sorted(set(pos_df_input["Explanation"]).union(set(pos_df_output["Explanation"])))

# Align frequencies to the unified list of explanations (fill missing values with 0)
input_frequencies = [
    pos_df_input.loc[pos_df_input["Explanation"] == explanation, "Frequency"].sum() if explanation in pos_df_input["Explanation"].values else 0
    for explanation in all_explanations
]
output_frequencies = [
    pos_df_output.loc[pos_df_output["Explanation"] == explanation, "Frequency"].sum() if explanation in pos_df_output["Explanation"].values else 0
    for explanation in all_explanations
]

# Combine data into a DataFrame for sorting
data = list(zip(all_explanations, input_frequencies, output_frequencies))
sorted_data = sorted(data, key=lambda x: x[1] + x[2], reverse=True)  # Sort by total frequency (descending)

# Unpack sorted data
sorted_explanations, sorted_input_frequencies, sorted_output_frequencies = zip(*sorted_data)

# Set bar positions
x = np.arange(len(sorted_explanations))  # X positions for the bars
width = 0.4  # Width of the bars

# Plot the bars
plt.figure(figsize=(12, 8))
plt.bar(x - width / 2, sorted_input_frequencies, width, label="General Input Tokens")
plt.bar(x + width / 2, sorted_output_frequencies, width, label="Influential Input Tokens")

# Add labels, title, and legend
plt.title("POS Distribution Comparison (Sorted by Total Frequency)")
plt.xlabel("Part of Speech")
plt.ylabel("Frequency")
plt.xticks(x, sorted_explanations, rotation=45, ha="right")
plt.legend(title="Token Type")
plt.tight_layout()
plt.show()





# Assume syntactic_results and High General/High Influential Input Tokens Syntax are predefined
dependency_counts_input = pd.Series(
    [entry["Dependency"] for syntax in syntactic_results["High General Input Tokens Syntax"] for entry in syntax]
).value_counts()

dependency_counts_output = pd.Series(
    [entry["Dependency"] for syntax in syntactic_results["High Influential Input Tokens Syntax"] for entry in syntax]
).value_counts()

# Create DataFrames for each
df_input = pd.DataFrame({
    "Dependency": dependency_counts_input.index,
    "Frequency": dependency_counts_input.values,
    "Explanation": dependency_counts_input.index.map(spacy.explain)
})

df_output = pd.DataFrame({
    "Dependency": dependency_counts_output.index,
    "Frequency": dependency_counts_output.values,
    "Explanation": dependency_counts_output.index.map(spacy.explain)
})

print("Dependency Frequency and Explanation for High Input Tokens:\n", df_input)
print("----------------------------------------------------------------------------")
print("Dependency Frequency and Explanation for High Output Tokens:\n", df_output)


import matplotlib.pyplot as plt
import numpy as np

# Align both DataFrames to ensure consistent x-axis (all dependencies included)
all_dependencies = sorted(set(df_input["Dependency"]).union(set(df_output["Dependency"])))

# Align frequencies to the unified list of dependencies (fill missing values with 0)
input_frequencies = [
    df_input.loc[df_input["Dependency"] == dep, "Frequency"].sum() if dep in df_input["Dependency"].values else 0
    for dep in all_dependencies
]
output_frequencies = [
    df_output.loc[df_output["Dependency"] == dep, "Frequency"].sum() if dep in df_output["Dependency"].values else 0
    for dep in all_dependencies
]

# Combine data into a list for sorting
data = list(zip(all_dependencies, input_frequencies, output_frequencies))

# Sort data by the total frequency (input + output) in descending order
sorted_data = sorted(data, key=lambda x: x[1] + x[2], reverse=True)

# Unpack sorted data
sorted_dependencies, sorted_input_frequencies, sorted_output_frequencies = zip(*sorted_data)

# Get corresponding explanations for the sorted dependencies
sorted_explanations = [
    df_input.loc[df_input["Dependency"] == dep, "Explanation"].values[0] if dep in df_input["Dependency"].values else
    df_output.loc[df_output["Dependency"] == dep, "Explanation"].values[0]
    for dep in sorted_dependencies
]

# Set bar positions
x = np.arange(len(sorted_dependencies))  # X positions for the bars
width = 0.4  # Width of the bars

# Plot the bars
plt.figure(figsize=(12, 8))
plt.bar(x - width / 2, sorted_input_frequencies, width, label="High General Input Tokens")
plt.bar(x + width / 2, sorted_output_frequencies, width, label="High Influential Input Tokens")

# Add labels, title, and legend
plt.title("Dependency Distribution Comparison")
plt.xlabel("Dependency Explanation")
plt.ylabel("Frequency")
plt.xticks(x, sorted_explanations, rotation=45, ha="right")
plt.legend(title="Token Type")
plt.tight_layout()  # Adjust layout to prevent overlap
plt.show()






